---
title: "Knowledge Representation and Reasoning"
permalink: /files/l9/
author_profile: false
---

## Knowledge

What is knowledge? According to Wikipedia:

*Knowledge is familiarity, awareness, or understanding of someone or something, such as facts, information, description, skills which is acquired through experience or education by perceiving discovering or learning.*

We can all agree that this is a very complicated definition. One widely accepted definition by philosophers is,

*Knowledge is knowing something to be true.*

 But, again, what does it mean to know something to be true? For a statement to be true, it has to meet following three criteria:
1.  The person believes the statement to be true.
1. The statement is in fact true.
1. The person is justified in believing the statement to be true.


Considering the following sentences:

- John knows that Mary will come to the party.
- John believes that Mary will come to the party.


The word "believes" is used to show that John is not  completely certain about Mary coming to the party.  In this course, we will not distinguish between belief and truth, that is between criteria (1) and (2).


Now, let us move our attention towards, "justification". The question here is, *how do we justify that something is true ?*

Aristotle is usually credited among Greek philosophers to recognize that reasoning or justification is about form. One of his famous syllogism:


<p align="center">
  All Greeks are human.<br>
  <span style="display: inline-block; text-align: center;">
    All humans are mortal.<br>
    <hr style="margin: 0 auto; width: 30%; border-style: solid; border-width: 2px;">
  </span>
  </p>
<p align="center">
  All Greeks are mortal.
</p>



But, it turns out that the justification is not only about the form of the sentences. Considering the following example:

<p align="center">
  Not all Greeks are human.<br>
  <span style="display: inline-block; text-align: center;">
    Not all human are mortal.<br>
    <hr style="margin: 0 auto; width: 30%; border-style: solid; border-width: 2px;">
  </span>
  </p>
<p align="center">
   Not all Greeks are mortal.
</p>
<p align="center" style="color: red;">
  [This is not correct.]
</p>



Almost 2000 years later, Boole realized that the statements are about the class of objects and his idea was to use symbolic variables. Boole's idea was to replace "Greeks" by $p$, "humans" by $q$, and "mortal" by $r$. Then, we essentially have:

<p align="center">
  If p then q (p ⇒ q)<br>
  <span style="display: inline-block; text-align: center;">
   If q then r (q ⇒ r)<br>
    <hr style="margin: 0 auto; width: 30%; border-style: solid; border-width: 2px;">
  </span>
  </p>
<p align="center">
   If p then r (p ⇒ r)
</p>


$p$, $q$, and $r$ are symbolic variables. A symbolic variable reflects some underlying quantity, which at this point is unknown. The possible values of these symbolic variables are the truth values.

At this point, let us first answer the important question that everyone of you must be thinking, "how does all of these relates to AI?"

Alan Turing first proposed the term "Machine Intelligence". In 1958, John McCarthy pro-posed in his paper "Programs with Common Sense", to use formal logic to represent information in computers.  According to McCarthy's paper, a program has common sense if it automatically deduces for itself a sufficiently wide class of immediate consequences of anything it is told and what it already knows.

|![Figure 1](/images/markdown-images/L9/program-common-sense.png "fig:")|
|:---:|
|*Figure 1: Programs with common sense*|





Figure 1 represent a program with common sense in a  AI system looks like. As shown in Figure 1, a knowledge-based system is able to make deductions from its database of knowledge. The deduction can then be added back to the database to be used for further deductions.

In this module, we will focus on the two boxes shown in Figure 1.
1.  How do we represent, what the system knows?
2. How do we deduce the consequences?


## Propositional Logic: Syntax and Semantics

In the previous section, we had discussed about symbolic variables and the usage of symbolic variables. Let us call them as propositional variables. A propositional variable is either true or false. We want to abstract away the arguments about whether certain things in the world are true, whether Crazy Rich Asians is a good movie or sky is blue. We can represent them with a proposition $p$ and then that proposition can take value true or false.


### Syntax
The first question concerns that, *what should we assign a variable?*. Let us consider the following the sentences:

- If taxi arrives on time then John and Mary will be at party.
- If John and Mary are at party then Jack is at party.
- If John is at party then Jack is at party.


What should we assign variables to represents the above mentioned sentences? Let us try to link this to object oriented programming, where we need to figure about what attributes do we want to have an object for. Similar to that, we assign propositional variables to all the "relevant" objects, their attributes and relationship,like:

- Man, Women, Student, Adult
- Mortal, Genius, Rich, Crazy
- Friends(John, Jack), Lovers(Romeo, Juliet)


Now, we have subject/object, but we also need verbs and punctuation. That is, to build a language from scratch, we need 3 component:
1.  **word:**
We use proposition. Propositions are statements that are true or false but not both. We denote PROP be the universal set of all propositions.
1. **verb:**
- Unary: "$\lnot$".
- Binary: "$\lor$", "$\land$", $\ldots$\\
 Henceforth, we use $\odot$ to represent binary operators.
3. **punctuation**: \{"(",")" \}


**Well Formed Formula (WFF)**

As we have all 3 component of our language, called propositional logic. Let us now try to frame a statement in our language.
$$\begin{align*}
\text{FORM}_{0} &= \text{PROP}\\
\text{FORM}_{i+1} &= \text{FORM}_{i} \cup \{ (\lnot \varphi); \varphi \in \text{FORM}_{i} \} \cup \{ (\alpha \odot \beta); \alpha, \beta \in \text{FORM}_{i}\}\\
\text{FORM} &= \cup_{i=0}^{\infty} \text{FORM}_{i}
\end{align*}$$

FORM is called a well-formed formulas (WFF). FORM defines all possible entries in our propositional logic.

For example: $(( p \lor q) \lor r)$, $(\lnot (p \lor q))$.

**Parsing of WFF**
Human languages often contain a lot of ambiguity, an example is the following valid English sentences:

- We saw her drunk.
- Every farmer who owns a donkey beats it.
- Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo

The above sentence is grammatically correct, but they all have multiple meanings associated with it. To avoid such ambiguity in propositional logic, we need further need to formalizes the formulas:

*Formulas are either atomic or composite.*
- The set of atomic formulas: PROP.
- For a composite formula ($\lnot \varphi$).

  - $\lnot$ is the primary connective.
  - $\varphi$ is the immediate sub formula.

- For a composite formula ($\psi \odot \varphi$).

  - $\odot$ is the primary connective.
  - $\psi$ and $\varphi$ are immediate sub formulas.




*(theorem)* **Unique Readability**:
Every composite formula $\varphi$ has a unique primary connective and well-formed sub formulas.


The important thing to notice here is, every composite formula has a unique ordering of primary connectives and a unique set of immediate sub-formulas.

Consider the example: $((p \land q) \lor r)$. Primary connective: $\lor$, Immediate sub-formulas $(p \land q)$.

### Semantics
We had propositions to capture possible worlds, but how do we talk about a particular world? Consider this example: She was the best software engineer the company ever had. Is this sentence true or false ? To give judgment about the sentence, we need to know who are we referring to in "she", "the company". Therefore, the question here is, *How do we capture different worlds?}.

Let us consider an example $\varphi:=$ The table is rectangular. Let us assume, we have a function $\tau$ that maps "The table" to your classroom's table. That is, $\tau$ exactly capture the world "the table", now can you identify whether $\varphi$ is true or not? Let us try to formalize this:

*(Definition)* $\tau$ is a function that maps the PROP to $\{0,1\}$, or $\tau \in 2^{\text{PROP}}$.


*(Definition)* Formula $\varphi$ is also a function that maps the $2^{\text{PROP}}$ to $\{0,1\}$, or $\varphi \in 2^{2^{\text{PROP}}}$.


Consider an example: PROP = $\{p,q\}$, $\varphi:= (p \lor q)$, and $\tau:= \{p \vdash 1, q \vdash 0\}$, then $\varphi(\tau) := (1 \lor 0) = 1$.
Again, notice that we can consider operators $\lnot, \land, \lor, \ldots$ as a functions. $\lnot: \{0,1\} \mapsto \{0,1\}$, $\land: \{0,1\}^2 \mapsto \{0,1\}$.

That is,

$$\begin{equation}
\varphi(\tau) :=
\begin{cases}
\tau(p) & \text{if } \varphi = p \in PROP\\
\lnot (\alpha(\tau)) & \text{}\\
\odot(\alpha(\tau),\beta(\tau)) & \text{}
\end{cases}
\end{equation}$$

Let us consider another example, $\varphi := ((p \lor q) \land r)$.

$$\begin{align*}
\varphi(\tau) &:= \land((p \lor q)(\tau), r(\tau)) \\
&:= \land(\lor(p(\tau),q(\tau), r(\tau)))
\end{align*}
$$

*(Definition)* A **truth assignment** $\tau$ satisfies formula $\varphi$ if and only if $\varphi(\tau)$ is $1$. We will use symbol $\models$, and say $\tau \models \varphi$ if and only if $\varphi(\tau) = 1$. If such a $\tau$ exists then we say $\varphi$ is **satisfiable**.

*(Definition)* A formula $\varphi$ is considered to be **valid** if for all $\tau$ in $2^{\text{PROP}}$, $\varphi(\tau)$ is $1$. We use the notation $\models \varphi$, that is, $\models \varphi \iff \underset{\tau \in 2^{\text{PROP}}}{\forall} \varphi(\tau) = 1$. Example: $p \lor \lnot p$.

*(Definition)* A formula $\varphi$ is considered to be **unsatisfiable** if there does not exists a $\tau$ in $2^{\text{PROP}}$ such that $\varphi(\tau)$ is $1$. We use the notation $\not \models \varphi$, that is, $\not \models \varphi \iff \underset{\tau \in 2^{\text{PROP}}}{\forall} \varphi(\tau) = 0$. Example: $p \land \lnot p$.


Observe that if $\varphi$ is unsatisfiable, then $(\lnot \varphi)$ is valid.

## First Order Logic
In normal speaking we could use logic to say something like: If all humans are mortal (say , $\alpha$) and all Greeks are human (say, $\beta$) then all Greeks are mortal (say, $\gamma$).  Therefore, if we have $\alpha$ = (H$\implies$ M) and $\beta$ = (G $\implies$ H) and $\gamma$ = (G$\implies$ M) (where H, M, G are propositions), we could say that
(($\alpha \wedge \beta$) $\implies \gamma$) is valid.

This is good because it allows us to focus on a true or false statement about one person. This kind of logic (propositional logic) was adopted by Boole (Boolean Logic)
But what about using "some" instead of "all" in $\beta$ in the statements above? Would the statement still hold? Consider the following example:

<p align="center">
  Someone is taller than me.<br>
  <span style="display: inline-block; text-align: center;">
   I am taller than someone.<br>
    <hr style="margin: 0 auto; width: 30%; border-style: solid; border-width: 2px;">
  </span>
  </p>
<p align="center" style="color: red;">
  I am taller than me?
</p>

What about we want to talk about statements like,
1. Best friend of John is Mary

   Without explicitly generating all propositions \{BestFriend(John, Mary)} = 1, BestFriend(John, Jake)} = 0\}. Can we represent it succinctly as \{BestFriend(John) = Mary\}} with an additional information that everyone has only one best friend?

   Furthermore, How can we express statements like,
2. For every student, there exists a course that is difficult for the student.

Where students and course are not concrete things. Let us try to come up basic element to represent statement like above.

**Elements of First Order Logic**
1. **Quantifiers:** $\forall, \exists$
2. **Variables:** $\{x, y, \ldots\}$ which are abstract objects which can take any value, not just 0 and 1.
3. **Predicates:** $P^{k}(t_1, \ldots, t_k): D^{k} \rightarrow \{0,1\}$ can take multiple arguments as inputs and always return true or false. $Brother(John, Jake)$ is a $2$-ary predicate. (Propositions are $0$-ary predicates)
4. **Functions:** $f^{k}(t_1, \ldots, t_k): D^{k} \rightarrow D$ can return any value. \\ A k-ary function is denoted as $f^{(k)}$. A 2-ary predicate is $f^{2}(x_1,x_2)$


### Semantics of First Order Logic

Consider the formula, $>(+(x, 2), 3)$ where $>$ is a predicate, $+$ is a function, $x$ is a variable and $2, 3$ are 0-ary functions. In order to evaluate this formula, an interpretation for the functions and predicates is required. Furthermore, a domain of values must also be defined. To define, we need the help of a **mathematical structure**, $\mathcal{A}$, which is expressed as:
$$\mathcal{A} = (\mathcal{D}, f_1^{k, A}, f_2^{k, A}, \dots, P_1^{k, A}, \dots) $$

When considering the assignment of values, it is important to first consider the mappings of predicates and functions:

$$\begin{align*}
f^{k}&: \mathcal{D}^k \rightarrow \mathcal{D} \\
P^k &: \mathcal{D}^k\rightarrow \{0, 1\}
\end{align*}
$$

Next, the functions must be defined such that it assigns values to the variables and terms in the formula. Consider the statement $A\models (x = 2)$. Does it make sense to ask whether the formula $x=2$ is true in the world $A$? The truth of the formula depends on the value of $x$, but $x$ is a variable and can take any value. Some values of $x$ might make the formula true, while others might falsify it. Thus, we need to qualify our answer by saying that the formula is true when $x$ has a certain value. To do this, we can use a function $\alpha$ that assigns values to variables. Such a function, $\alpha$, is called a `binding'. Thus, statements about semantics have the form $A,\alpha \models \phi$ where $A$ is a structure, $\phi$ is a formula and $\alpha$ is a variable assignment, i.e.,
$\alpha:Var\rightarrow D$. Note that our notion of truth is now a ternary relation, as opposed to the binary relation of propositional logic.

Let us now define above mentioned notion formally. First, we need to extend the notion of bindings to terms.
*(Definition)* Given structure $A$ and $\alpha:Var\rightarrow D$, we define $\overline{\alpha}:Term \rightarrow D$ as follows:

1. $\overline{\alpha}(x) = \alpha(x)$, where $x$ is a variable
1. $\overline{\alpha}(f(t_1,\dotsc,t_k)) =
f^A(\overline{\alpha}(t_1),\dotsc,\overline{\alpha}(t_k))$, where $k$ is the arity of $f$, and $t_1, \ldots, t_k \in \text{Terms}$.


Note that if $f$ is a $0$-ary function then $\overline{\alpha}(f) =f^A$.

We can think of an assignment as an array. If $\alpha(x_i)=a_i$, an assignment to $x_1,\ldots,x_n$ is the array $[a_1,\ldots,a_n]$. Therefore, $\alpha[x_i\mapsto a'_i]$ simply updates the $i$th entry of the array.

$$\begin{align*}
\alpha &: \textrm{Vars} \rightarrow \mathcal{D} \\
\bar{\alpha} &: \textrm{TERM} \rightarrow \mathcal{D} \\
\end{align*}
$$

The assignment of $\bar{\alpha}(f^k(t_1, \dots t_k))$ can evaluated as follows:
$$\begin{align*}
\bar{\alpha}(f^k(t_1, \dots t_k)) = f^k(\bar{\alpha}(t_1), \dots \bar{\alpha}(t_k))
\end{align*}$$

Semantics relates the syntax to the world (relational structure). $A\models \phi$ denotes that formula $\phi$ is true in the world $A$. Here `$\models$' is the semantical relation.

### Satisfiability of First Order Logic
Now that a mathematical structure and a function for the assignment have been defined, satisfiability can now be considered. Let's consider the different possible formulas for satisfiability given $\mathcal{A}$ and $\alpha$.
1.  $\mathcal{A}, \alpha \models P^k(t_1, \dots, t_k) \leftrightarrow P^k(\bar{\alpha}(t_1), \dots, \bar{\alpha}(t_k)) = 1$
1. $\mathcal{A}, \alpha \models (\varphi \lor \psi) \leftrightarrow (\mathcal{A}, \alpha \models \varphi) \lor (\mathcal{A}, \alpha \models \psi)$
1. $\mathcal{A}, \alpha \models (\varphi \land \psi) \leftrightarrow (\mathcal{A}, \alpha \models \varphi) \land (\mathcal{A}, \alpha \models \psi)$
1. $\mathcal{A}, \alpha \models (\lnot \varphi) \leftrightarrow \mathcal{A}, \alpha \not\models \varphi$
1. $\mathcal{A}, \alpha \models \exists x \varphi \leftrightarrow \exists v \in \mathcal{D}: \mathcal{A}, \alpha[x \mapsto v] \models \varphi$
1. $\mathcal{A}, \alpha \models \forall x \varphi \leftrightarrow \forall v \in \mathcal{D}: \mathcal{A}, \alpha[x \mapsto v] \models \varphi$



Let us consider $\varphi = (x < 2) \land (\exists x: ((x + 2) > 3))$ where $\mathcal{A} = (\mathbb{N}, <^\mathcal{A}, \dots)$ and $\alpha[x] = 1$. It can be seen that $\mathcal{A}, \alpha \models \varphi$ as $(x < 2)$ is satisfied with this assignment of $x$, whereas $(\exists x: ((x + 2) > 3))$ can be satisfied by overriding $\alpha[x]$ with another value that satisfies this equation. Therefore, it is possible that $\varphi$ is satisfiable.

<!-- ### Relevance Lemma}

agraph{Free and Bound Variables}
For any first order logic, $\phi$, let $FVars(\varphi) \in 2^{Vars}$ denote the set of free variables of $\varphi$. Let us recursively define $FVars(t)$ for any term $t \in Term$, and $FVars(\varphi)$:

- For any $x \in Vars$, $FVars(x) = \{x\}$.
- For any $f \in Function$, $FVars(f(t_1,...,t_{k_f})) = \bigcup_i FVars(t_i)$. This covers all terms.
- For any $P \in Predicate$, $FVars(P(t_1,...,t_{k_P})) = \bigcup_i FVars(t_i)$.
- $FVars(\neg \varphi) = FVars(\varphi)$.
- For any logical connective $\circ$, $FVars(\alpha \circ \beta) = FVars(\alpha) \cup FVars(\beta)$.
- For any quantifier $\# \in \{\forall, \exists\}$ and variable $x \in Vars$, $FVars(\# x : \varphi) = FVars(\varphi) \setminus \{x\}$.


\begin{theorem} (Relevance Lemma for first order logic)
Fix the structure $\mathcal{A}$. Let us consider a formula $\varphi$. Let $\alpha_1, \alpha_2 \in \mathcal{D}^{Vars}$ be two variable assignments on $\mathcal{A}$.
If for all $x \in Vars$, $\alpha_1[x] = \alpha_2[x]$, then $\mathcal{A}, \alpha_1 \models \varphi$ iff $\mathcal{A}, \alpha_2 \models \varphi$.\footnote{Proof is taken from Lim Fong Yuan's class scribe.}
\end{theorem}

\begin{proof}
By induction on $Term$ then on $Form$.

- For any $x \in FVars(\varphi)$, $\bar{\alpha_1}(x) = \alpha_1(x) = \alpha_2(x) = \bar{\alpha_2}(x)$.

- For any $f \in Functions$ that appears in $\varphi$, $\bar{\alpha_1}(f^\mathcal{A}(t_1,...,t_{k_f})) = f^\mathcal{A}(\bar{\alpha_1}(t_1),...,\bar{\alpha_1}(t_{k_f})) = f^\mathcal{A}(\bar{\alpha_2}(t_1),...,\bar{\alpha_2}(t_{k_f})) = \bar{\alpha_2}(f^\mathcal{A}(t_1,...,t_{k_f}))$. This covers all terms.

- For any $P \in Predicate$ that appears in $\varphi$, $\mathcal{A}, \alpha_1 \models P(t_1,...,t_{k_f})$ iff $1 = P^\mathcal{A}(\bar{\alpha_1}(t_1),...,\bar{\alpha_1}(t_{k_f})) = P^\mathcal{A}(\bar{\alpha_2}(t_1),...,\bar{\alpha_2}(t_{k_f}))$ iff $\mathcal{A}, \alpha_2 \models P(t_1,...,t_{k_f})$.

- $\mathcal{A}, \alpha_1 \models (\neg \psi)$ iff $\mathcal{A}, \alpha_1 \not \models \psi$ iff $\mathcal{A}, \alpha_2 \not \models \psi$ iff $\mathcal{A}, \alpha_2 \models (\neg \psi)$.

- For any logical connective $\circ$, $\mathcal{A}, \alpha_1 \models (\beta \circ \gamma)$ iff $(\mathcal{A}, \alpha_1 \models \beta) \circ (\mathcal{A}, \alpha_1 \models \gamma)$ iff $(\mathcal{A}, \alpha_2 \models \beta) \circ (\mathcal{A}, \alpha_2 \models \gamma)$ iff $\mathcal{A}, \alpha_2 \models (\beta \circ \gamma)$.

- For any variable $x \in Vars$, $\mathcal{A}, \alpha_1 \models (\forall x : \varphi)$ iff [for all $v \in \mathcal{D}$, $\mathcal{A}, \alpha_{1,x \mapsto v} \models \varphi$] iff [for all $v \in \mathcal{D}$, $\mathcal{A}, \alpha_{2,x \mapsto v} \models \varphi$] iff $\mathcal{A}, \alpha_2 \models (\forall x : \phi)$. Similar for $\exists$.

\end{proof}

In general, we do not even need the structures $\mathcal{A}$ paired with $\alpha_1$ and $\alpha_2$ to be the same; we simply need $\mathcal{A}_1$ and $\mathcal{A}_2$ to agree on the meaning of all the functions and predicates appearing in $\varphi$.

Let $\mathcal{A}$ be given. For any formula $\varphi$,

- $\varphi$ is **satisfiable}, if there exists a variable assignment $\alpha$ such that $\mathcal{A},\alpha \models \varphi$.
- $\varphi$ is **valid}, if for all variable assignments $\alpha$, $\mathcal{A},\alpha \models \varphi$. We also call $\varphi$ a **sentence}.
- $\varphi$ is **unsatisfiable}, if for all variable assignments $\alpha$, $\mathcal{A},\alpha \not \models \varphi$.


By assuming $\mathcal{A}$ to be finite, Algorithm~\ref{algo:checksatfol} represents the algorithm for checking the satisfiability of given formula $\varphi$.

\begin{algorithm}[H]

\caption{CheckSAT{($\mathcal{A},\varphi$)}\label{algo:checksatfol}}
\begin{algorithmic}[1]
\For { $\alpha \in \mathcal{D}^{Vars}$}
\If {$\mathcal{A}, \alpha \models \varphi $}
\State
\Return {True}

\EndIf
\EndFor
\State
\Return {{False}}
\end{algorithmic}
\end{algorithm}

Similarly with minor change in Algorithm~\ref{algo:checksatfol}, we can compute the model count of $\varphi$. Algorithm~\ref{algo:countfol}.

\begin{algorithm}[H]

\caption{ModelCount{($\mathcal{A},\varphi$)}\label{algo:countfol}}
\begin{algorithmic}[1]
\State Models := [\;]
\For { $\alpha \in \mathcal{D}^{Vars}$}
\If {$\mathcal{A}, \alpha \models \varphi $}
\State
\Return {models.append($\alpha$)}

\EndIf
\EndFor
\State
\Return {models}
\end{algorithmic}
\end{algorithm}
The complexity of both $CheckSAT(,)$ and $ModelCompute(,)$ is $O((|\mathcal{A}|+|\alpha|+|\varphi|)^{|\varphi|})$.
% ### Higher Order Logics}

% It is interesting to observe the following hierarchy of logics and logic formulas.  First we have first-order logic which is concerned with variables(**V}), while for second-order logic the elementary elements are sets of variables($2^{\mathbf{V}}$), while in third-order logic the main objects are sets of sets of variables ($2^{2^{\mathbf{V}}}$).
% In First Order logic quantifiers ($\forall$, $\exists$) quantify over elements (Variables), while in Second Order logic quantifiers are over sets of variables and in Third Order the quantifiers are over sets of sets of variables.  The entire system taken together is called *type theory}. -->
